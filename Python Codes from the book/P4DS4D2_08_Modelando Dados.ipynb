{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'First'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'First'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m     row_s\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m obj[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mtext\n\u001b[0;32m     16\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([df, row_s], axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(df\u001b[39m.\u001b[39;49mloc[\u001b[39m'\u001b[39;49m\u001b[39mFirst\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39m\u001b[39mNumber\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[0;32m     19\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(df\u001b[39m.\u001b[39mloc[\u001b[39m'\u001b[39m\u001b[39mFirst\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mBoolean\u001b[39m\u001b[39m'\u001b[39m]))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1100\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m   1102\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[1;32m-> 1103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexing.py:1343\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1341\u001b[0m \u001b[39m# fall thru to straight lookup\u001b[39;00m\n\u001b[0;32m   1342\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1343\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label(key, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexing.py:1293\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_label\u001b[39m(\u001b[39mself\u001b[39m, label, axis: AxisInt):\n\u001b[0;32m   1292\u001b[0m     \u001b[39m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[1;32m-> 1293\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49mxs(label, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:4095\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   4093\u001b[0m             new_index \u001b[39m=\u001b[39m index[loc]\n\u001b[0;32m   4094\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4095\u001b[0m     loc \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   4097\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(loc, np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m   4098\u001b[0m         \u001b[39mif\u001b[39;00m loc\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mbool_:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'First'"
     ]
    }
   ],
   "source": [
    "from lxml import objectify\n",
    "import pandas as pd\n",
    "from distutils import util\n",
    "\n",
    "xml = objectify.parse(open('..\\PythonDataScienceFD_arquivo_online\\XMLData.xml'))\n",
    "root = xml.getroot()\n",
    "df = pd.DataFrame(columns=('Number', 'Boolean'))\n",
    "\n",
    "for i in range(0, 4):\n",
    "    obj = root.getchildren()[i].getchildren()\n",
    "    row = dict(zip(['Number', 'Boolean'], \n",
    "                   [obj[0].pyval, \n",
    "                    bool(util.strtobool(obj[2].text))]))\n",
    "    row_s = pd.Series(row)\n",
    "    row_s.name = obj[1].text\n",
    "    df = pd.concat([df, row_s], axis = 1)\n",
    "    \n",
    "print(type(df.loc['First']['Number']))\n",
    "print(type(df.loc['First']['Boolean']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Number  Boolean\n",
      "First        1     True\n",
      "Second       2    False\n",
      "Third        3     True\n",
      "Fourth       4    False\n",
      "******************************\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.bool_'>\n"
     ]
    }
   ],
   "source": [
    "from lxml import objectify\n",
    "import pandas as pd\n",
    "from distutils import util\n",
    "\n",
    "xml = objectify.parse(open('..\\PythonDataScienceFD_arquivo_online\\XMLData.xml'))\n",
    "root = xml.getroot()\n",
    "\n",
    "map_number = map(int, root.xpath('Record/Number'))\n",
    "map_bool = map(str, root.xpath('Record/Boolean'))\n",
    "map_bool = map(util.strtobool, map_bool)\n",
    "map_bool = map(bool, map_bool)\n",
    "map_string = map(str, root.xpath('Record/String'))\n",
    "\n",
    "data = list(zip(map_number, map_bool))\n",
    "\n",
    "df = pd.DataFrame(data,\n",
    "                  columns=('Number', 'Boolean'),\n",
    "                  index = list (map_string))\n",
    "\n",
    "print(df)\n",
    "print('*'*30)\n",
    "print(type(df.loc['First']['Number']))\n",
    "print(type(df.loc['First']['Boolean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW shape: (2356, 34750)\n",
      "******************************\n",
      "\"Caltech\": 3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "categories = ['comp.graphics', 'misc.forsale',\n",
    "              'rec.autos', 'sci.space']\n",
    "\n",
    "twenty_train = fetch_20newsgroups(subset='train',\n",
    "                                  categories=categories,\n",
    "                                  shuffle=True,\n",
    "                                  random_state=42)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(\n",
    "    twenty_train.data)\n",
    "\n",
    "print(\"BOW shape:\", X_train_counts.shape)\n",
    "caltech_idx = count_vect.vocabulary_['caltech']\n",
    "print('*'*30)\n",
    "print('\"Caltech\": %i' % X_train_counts[0, caltech_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' an' ' in' ' of' ' th' ' to' 'he ' 'ing' 'ion' 'nd ' 'the']\n",
      "[[0 0 2 5 1 4 2 2 0 5]]\n",
      "['anonymous ftp' 'commercial space' 'gamma ray' 'nasa gov'\n",
      " 'national space' 'remote sensing' 'sci space' 'space shuttle'\n",
      " 'space station' 'washington dc']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "categories = ['sci.space']\n",
    "\n",
    "twenty_train = fetch_20newsgroups(subset='train', \n",
    "                                  categories=categories, \n",
    "                                  remove=('headers', \n",
    "                                          'footers', \n",
    "                                          'quotes'),\n",
    "                                  shuffle=True, \n",
    "                                  random_state=42)\n",
    "\n",
    "count_chars = CountVectorizer(analyzer='char_wb', \n",
    "                              ngram_range=(3,3), \n",
    "                              max_features=10)\n",
    "\n",
    "count_chars.fit(twenty_train['data'])\n",
    "\n",
    "count_words = CountVectorizer(analyzer='word', \n",
    "                              ngram_range=(2,2),\n",
    "                              max_features=10,\n",
    "                              stop_words='english')\n",
    "\n",
    "count_words.fit(twenty_train['data'])\n",
    "\n",
    "X = count_chars.transform(twenty_train.data)\n",
    "\n",
    "print(count_chars.get_feature_names_out())\n",
    "print(x[1].todense())\n",
    "print(count_words.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anonymous ftp' 'commercial space' 'gamma ray' 'nasa gov'\n",
      " 'national space' 'remote sensing' 'sci space' 'space shuttle'\n",
      " 'space station' 'washington dc']\n",
      "[[0 0 2 5 1 4 2 2 0 5]]\n",
      "['anonymous ftp' 'commercial space' 'gamma ray' 'nasa gov'\n",
      " 'national space' 'remote sensing' 'sci space' 'space shuttle'\n",
      " 'space station' 'washington dc']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "categories = ['sci.space']\n",
    "\n",
    "twenty_train = fetch_20newsgroups(subset='train', \n",
    "                                  categories=categories, \n",
    "                                  remove=('headers', \n",
    "                                          'footers', \n",
    "                                          'quotes'),\n",
    "                                  shuffle=True, \n",
    "                                  random_state=42)\n",
    "\n",
    "count_chars = CountVectorizer(analyzer='char_wb', \n",
    "                              ngram_range=(3,3), \n",
    "                              max_features=10)\n",
    "\n",
    "count_chars.fit(twenty_train['data'])\n",
    "\n",
    "count_words = CountVectorizer(analyzer='word', \n",
    "                              ngram_range=(2,2),\n",
    "                              max_features=10,\n",
    "                              stop_words='english')\n",
    "\n",
    "count_words.fit(twenty_train['data'])\n",
    "\n",
    "X = count_chars.transform(twenty_train.data)\n",
    "\n",
    "print(count_words.get_feature_names_out())\n",
    "print(X[1].todense())\n",
    "print(count_words.get_feature_names_out())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
